# STA 380: Predictive Modeling, Part 2

## Course details

* Instructor: James Scott (james.scott@mccombs.utexas.edu)
* Office hours: Monday, Tuesday, and Wednesday 12-1 PM (immediately after class, except on Thursday)
* Office: CBA 6.478
* Course website: http://www.github.com/jgscott/STA380/

## Overview

This is the second half of a two-part introductory course on predictive modeling for students in the MS program in Business Analytics at UT-Austin.  In the first half of the course, you learned about predictive models for labeled data (i.e. regression or supervised learning).  In the second half, you will learn about modeling structure in _unlabeled_ data (i.e. unsupervised learning).  The course is intended as an overview, rather than an in-depth treatment of any particular topic.  We will move fast and cover a lot, but will focus on practical applications rather than theory.

## Software

* Statistical computing: [R](http://www.r-project.org), which we will use via [RStudio](http://www.rstudio.com), a free, platform-independent graphical front-end for R.  Make sure you have both installed, along with the [RMarkdown package](http://rmarkdown.rstudio.com).  
* Other software: please [install Git and create a GitHub account](https://help.github.com/articles/set-up-git/).  You will use GitHub for version control and to submit your assignments.  

## Grading  

The bulk of your grade will come from two long homework assignments (40% each), in which you will analyze some data, create a fully reproducible report using RMarkdown, and submit your report through GitHub.  The first assignment will be due on August 6th, and the second on August 14th.

The remaining 20% of your grade will come from submitting a high-quality scribe report for a single lecture.  I'll explain more about this in class, but the idea is simple: each day, someone takes detailed notes and makes them available to their classmates.  These notes are supposed to be definitive, by which I mean: comprehensive, mistake--free, and easily understood by any of your classmates who paid attention that day.  You only have to do this once, but you'll be repaid with a set of high-quality crowdsourced lecture notes.  I'll circulate a sign-up sheet for scribing on the first day of class.  


## Readings

The course readings are assembled from sources matching two criteria: 1) high quality, and 2) free. 

* _ISL_: Selections from _An Introduction to Statistical Learning_ by James, Witten, Hastie, and Tibshirani.  The book is [freely available here](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Fourth%20Printing.pdf).  I'll refer to it as "ISL" in the course outline.  
* _Elements_: selections from [_Elements of Statistical Learning_](http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf), by Hastie, Tibshirani, and Friedman.  A standard reference on data mining from a more statistical perspective.  Referrered to as "Elements" in the course outline.  
* _Shalizi_: selections from [Advanced Data Analysis from an Elementary Point of View](http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/ADAfaEPoV.pdf), by Cosma Shalizi.  Another textbook whose author has kindly posted a free version on the web.  Referred to as "Shalizi" in the course outline.  
* NIST Engineering Statistics Handbook, [Chapter 1](http://www.itl.nist.gov/div898/handbook/eda/eda.htm).  Yes, this webpage has a "Geocities circa 1998" look to it, but its discussion of exploratory data analysis is at least as good as anything you have to pay for.  
* Other smaller-format readings on a case-by-case basis.  



