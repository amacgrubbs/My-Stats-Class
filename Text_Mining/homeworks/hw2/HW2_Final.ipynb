{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zach Aldrich  \n",
    "Alec Grubbs  \n",
    "James Krach  \n",
    "Brian Lakey  \n",
    "Greg Merchant  \n",
    "Francisco Sananez  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('Yelp Data Restaurant Reviews Ratings.csv')\n",
    "yelp['target'] = (yelp['stars']>3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numerics = ['votes_cool','votes_funny','votes_useful',\n",
    "            'Moderate','Expensive','VeryExpensive','American',\n",
    "            'Chinese','French','Japanese','Indian','Italian',\n",
    "            'Greek','Mediterranean','Mexican','Thai','Vietnamese','Others']\n",
    "yelp_numerics = yelp[numerics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the text (reviews) and run a classification model with the numeric data (you can use standard methods like logistic regression, k-nearest neighbors or anything else). What is the best accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_numeric = LogisticRegression()\n",
    "rf_numeric = RandomForestClassifier(n_estimators=20)\n",
    "ab_numeric = AdaBoostClassifier(RandomForestClassifier(n_estimators=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 10-fold cross validated accuracy: 0.682335594821\n",
      "Random Forest 10-fold cross validated accuracy: 0.657338840247\n"
     ]
    }
   ],
   "source": [
    "lr_num_cv = cross_val_score(lr_numeric, yelp_numerics, y=yelp['target'], cv=10, n_jobs=-1)\n",
    "rf_num_cv = cross_val_score(rf_numeric, yelp_numerics, y=yelp['target'], cv=10, n_jobs=-1)\n",
    "\n",
    "print \"Logistic Regression 10-fold cross validated accuracy: \" + str(sum(lr_num_cv)/len(lr_num_cv))\n",
    "print 'Random Forest 10-fold cross validated accuracy: ' + str(sum(rf_num_cv)/len(rf_num_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Random Forest 10-fold cross validated accuracy: 0.653887589447\n"
     ]
    }
   ],
   "source": [
    "ab_num_cv = cross_val_score(ab_numeric, yelp_numerics, y=yelp['target'], cv=10, n_jobs=-1)\n",
    "print \"Boosted Random Forest 10-fold cross validated accuracy: \" + str(sum(ab_num_cv)/len(ab_num_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy of a model we tested was Logistic Regression, which provided about 68% accuracy. This is only slightly better than simply guessing that all restaurants are high quality (since the data is split 65:35)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a supervised classification on a subset of the corpus using the reviews only. You can write your code in Python or R. What accuracy do you get from this text mining exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = TfidfVectorizer(stop_words='english',\n",
    "                       min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_text = corpus.fit_transform(yelp['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boosted_forests_text = AdaBoostClassifier(RandomForestClassifier(n_estimators=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_cv_score = cross_val_score(boosted_forests_text, yelp_text, y=yelp['target'], cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Random Forests 10-fold cross validated accuracy on reviews: 0.789592763398\n"
     ]
    }
   ],
   "source": [
    "print \"Boosted Random Forests 10-fold cross validated accuracy on reviews: \" + str(sum(text_cv_score)/len(text_cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of a text only classifier is about 79%, which is high, but not much higher than the baseline rate that would be expected from guessing all restaurants are high (since the data is split 65:35). Regardless, the model works and is relatively effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the numeric data and the text classification model (in task B) to create a hybrid model. It is your task to figure out how to do this. Now run this hybrid classification model and compare the results with those in A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, yelp_numText, y_train, yelp_numText_target = train_test_split(pd.concat([yelp_numerics, yelp['Review']], axis=1), yelp['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_prediction_corpus = TfidfVectorizer(stop_words='english',\n",
    "                       min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_prediction_dtm = text_prediction_corpus.fit_transform(X_train['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_prediction_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_prediction_model = text_prediction_classifier.fit(text_prediction_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_text_smaller = text_prediction_corpus.transform(yelp_numText['Review'])\n",
    "predictions = text_prediction_model.predict(yelp_text_smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp_numText = yelp_numText[numerics]\n",
    "yelp_numText['text_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosted Random Forest 10-fold cross validated hybrid model accuracy: 0.828395989584\n"
     ]
    }
   ],
   "source": [
    "ab_hybrid = AdaBoostClassifier(RandomForestClassifier(n_estimators=20))\n",
    "ab_hybrid_cv = cross_val_score(ab_hybrid, yelp_numText, y=yelp_numText_target, cv=10, n_jobs=-1)\n",
    "print \"Boosted Random Forest 10-fold cross validated hybrid model accuracy: \" + str(sum(ab_hybrid_cv)/len(ab_hybrid_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the purely numeric models from A perform around 65% accuracy and the purely text based model performs at around 79% accuracy, the hybrid model performs far better at around 83% since it incorporates data from both types of models. This indicates that text data provides additional information that cannot be captured in the numeric data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use unsupervised sentiment analysis on the reviews (with SentiStrength or any other tool) and use the sentiment score to predict high/low rating. Compare and contrast the results of tasks B and D. What can you conclude from your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_sent(review):\n",
    "    review = review.encode('string-escape')\n",
    "    blob = TextBlob(review)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp['review_sent'] = yelp['Review'].map(review_to_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp['sent_classification'] = yelp['review_sent']>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm_sentiment_1 = confusion_matrix(yelp['target'], yelp['sent_classification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment based classification scheme accuracy: 0.722\n"
     ]
    }
   ],
   "source": [
    "print \"Sentiment based classification scheme accuracy: \" + str(round((cm_sentiment_1[0][0]+cm_sentiment_1[1][1])/float((sum(cm_sentiment_1[0])+sum(cm_sentiment_1[1]))), 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of a purely sentiment based classification scheme is lower than a bag-of-words model. This is likely because the word sentiment (in the case of this program and the case of SentiStrength) is based on a collection of words and sentiments that are not immediately relevant to this particular corpus (i.e. yelp restaurant reviews). Any accurate word sentiment based classification scheme needs to have training data that is related in some way to the corpus being tested, so if that were the case it would just be easier to use a bag-of-words model. Often, the absolute sentiment of a word is not the same as the context-based sentiment of a word. The accuracy achieved by Part B was higher since it took into account the context and wording of the reviews, but Part B was also far more computationally intensive than Part D, so there is a clear tradeoff to using a more specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use unsupervised clustering on the text. Does clustering achieve good separation between high and low rated restaurants? How can you explain the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_corpus = TfidfVectorizer(stop_words='english',\n",
    "                                 min_df=5,\n",
    "                                 max_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_text_cluster = cluster_corpus.fit_transform(yelp['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_cluster = KMeans(n_clusters=2, n_jobs=-1)\n",
    "clusters = kmeans_cluster.fit(yelp_text_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_entropy = normalized_mutual_info_score(yelp['target'], clusters.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized entropy of clusters is: 0.0305\n"
     ]
    }
   ],
   "source": [
    "print \"The normalized entropy of clusters is: \" + str(round(cluster_entropy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the text data performs very poorly when trying to force clustering into high and low rated reviews. This is likely because while there are clusters, it is difficult to cluster on two specific features. Additionally, the text data has to have at least 100 dimensions to say anything meaningful about the documents, and trying to measure distance in high dimensional space with a simple clustering algorithm is extremely difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top 5 attributes of a restaurant that are associated with (i) high and (ii) low ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_hybrid.fit(yelp_numText, yelp_numText_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('votes_useful', 0.23786825687164273)\n",
      "('votes_cool', 0.13511610472757099)\n",
      "('votes_funny', 0.10750255367262984)\n",
      "('text_predictions', 0.10395620534159045)\n",
      "('Moderate', 0.085149482681453309)\n"
     ]
    }
   ],
   "source": [
    "feature_importances = []\n",
    "for i in range(len(yelp_numText.columns)):\n",
    "    feature_importances.append((yelp_numText.columns[i], ab_hybrid.feature_importances_[i]))\n",
    "ordered_feature_importances = sorted(feature_importances, key=lambda x: x[1])[::-1]\n",
    "for i in range(5):\n",
    "    print ordered_feature_importances[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_forests_text.fit(yelp_text, y=yelp['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'05', 3.0496556863730767e-07)\n",
      "(u'02', 4.4864205158504963e-07)\n",
      "(u'07', 6.1475414279939689e-07)\n",
      "(u'06', 6.6888815875615668e-07)\n",
      "(u'04', 9.4404560616427456e-07)\n"
     ]
    }
   ],
   "source": [
    "text_feature_importances = []\n",
    "for i in range(len(yelp_numText.columns)):\n",
    "    text_feature_importances.append((corpus.get_feature_names()[i], boosted_forests_text.feature_importances_[i]))\n",
    "ordered_text_feature_importances = sorted(text_feature_importances, key=lambda x: x[1])\n",
    "for i in range(5):\n",
    "    print ordered_text_feature_importances[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'00', 0.00035484546925930731)\n",
      "(u'10', 0.00020311674798398523)\n",
      "(u'100', 2.9762992173300608e-05)\n",
      "(u'09', 1.5337025121344874e-05)\n",
      "(u'03', 7.7907334843650031e-06)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print ordered_text_feature_importances[::-1][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words that are most indicative of low and high rated restaurants are listed above, but since these featues are fairly non-descriptive, it is also meaningful to look at the features of the hybrid model at the top. So the most important features for determining if a review will be either highly rated or low rated are how useful, cool, and funny a review is. These features are somewhat unsurprising since they are in a way meta-reviews. It is also unsurprising that the prediction from the text model is the next most indicative feature since it is also an analysis of many reviews and a prediction based on an entire training set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
